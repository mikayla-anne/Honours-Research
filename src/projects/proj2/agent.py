#!/usr/bin/env python3
from pyrsistent import PMap

from src.lib.game.discrete_soccer import Action
from ...lib.game import Agent, RandomAgent, GameState


class MinimaxAgent(RandomAgent):
    """An agent that makes decisions using the Minimax algorithm, using a
    evaluation function to approximately guess how good certain states
    are when looking far into the future.

    :param evaluation_function: The function used to make evaluate a
        GameState. Should have the parameters (state, player_id) where
        `state` is the GameState and `player_id` is the ID of the
        player to calculate the expected payoff for.

    :param alpha_beta_pruning: True if you would like to use
        alpha-beta pruning.

    :param max_depth: The maximum depth to search using the minimax
        algorithm, before using estimates generated by the evaluation
        function.
    """

    def __init__(self, evaluate_function, alpha_beta_pruning=False, max_depth=5):
        super().__init__()
        self.evaluate = evaluate_function
        self.alpha_beta_pruning = alpha_beta_pruning
        self.max_depth = max_depth

    def decide(self, state: GameState):
        if state is None:
            print("STATE IS NONE")
        else:
            print("state is fine")
        # TODO: Implement this agent!
        #
        # Read the documentation in /src/lib/game/_game.py for
        # information on what the decide function does.
        #
        # Do NOT call the soccer evaluation function that you write
        # directly from this function! Instead, use
        # `self.evaluate`. It will behave identically, but will be
        # able to work for multiple games.
        #
        # Do NOT call any SoccerState-specific functions! Assume that
        # you can only see the functions provided in the GameState
        # class.
        #
        # If you would like to see some example agents, check out
        # `/src/lib/game/_agents.py`.

        if not self.alpha_beta_pruning:
            return self.minimax(state)
        else:
            return self.minimax_with_ab_pruning(state)

    def minimax(self, state: GameState):
        # This is the suggested method you use to do minimax.  Assume
        # `state` is the current state, `player` is the player that
        # the agent is representing (NOT the current player in
        # `state`!)  and `depth` is the current depth of recursion.
        # return super().decide(state)

        best_action = None
        best_score = float("-inf")
        for index, action in enumerate(state.actions):

            # print(str(action) + " score: " + str(self.evaluate(state.act(action), state.current_player)))
            new_state = state.act(action)
            if new_state is not None:
                # print(new_state)
                score = self.min_value(new_state, state.current_player)
                # score = self.evaluate(state.act(action), state.current_player)
                print(str(action) + ": " + str(score))
                if score > best_score:
                    best_action = action
                    best_score = score
        return best_action

    def minimax_with_ab_pruning(self, state):
        print("WITH AB PRUNING")
        best_action = None
        best_score = float("-inf")
        for index, action in enumerate(state.actions):

            # print(str(action) + " score: " + str(self.evaluate(state.act(action), state.current_player)))
            new_state = state.act(action)
            if new_state is not None:
                # print(new_state)
                print(str(action))
                score = self.min_value(new_state, state.current_player, pruning=True, alpha=best_score, beta=float("inf"))
                # score = self.evaluate(state.act(action), state.current_player)
                print(str(action) + ": " + str(score))
                if score > best_score:
                    best_action = action
                    best_score = score
        return best_action

    def min_value(self, state: GameState, player, depth: int = 1, pruning: bool = False, alpha: float = float("-inf"),
                  beta: float = float("inf")):
        # TODO un-combine reward and evaluation
        # print(state)

        spaces = ""
        for i in range(0, depth):
            spaces += "    "

        # If at a terminal state, return the reward
        if state.is_terminal:
            return state.reward(player) + self.evaluate(state, player)
        # If we reached the max search depth, return the utility
        if depth >= self.max_depth:
            return self.evaluate(state, player)

        smallest_score = float("inf")
        for index, action in enumerate(state.actions):
            new_state = state.act(action)
            if new_state is not None:
                #print(str(spaces) + str(alpha) + ", " + str(beta))
                #print(spaces + str(action))
                score = self.max_value(new_state, player, depth=depth + 1, pruning=pruning, alpha=alpha, beta=beta)
                #print(spaces + str(action) + ": " + str(score))
                if score < smallest_score:
                    #print(spaces + "New Smallest Score")
                    smallest_score = score
            if pruning:
                if smallest_score <= alpha:
                    #print(spaces + "pruned")
                    #print(spaces + "score: " + str(smallest_score) + " <= alpha: " + str(alpha))
                    return smallest_score

                beta = min(beta, smallest_score)
                #if smallest_score < beta:
                    #print(spaces + "Beta: " + str(beta))
        return smallest_score

    def max_value(self, state: GameState, player, depth: int = 1, pruning: bool = False, alpha: float = float("-inf"),
                  beta: float = float("inf")):
        # print(state)
        spaces = ""
        for i in range(0, depth):
            spaces += "    "
        # If at a terminal state, return the reward
        if state.is_terminal:
            return state.reward(player) + self.evaluate(state, player)
        # If we reached the max search depth, return the utility
        if depth >= self.max_depth:
            return self.evaluate(state, player)

        biggest_score = float("-inf")
        for index, action in enumerate(state.actions):
            new_state = state.act(action)
            if new_state is not None:
                #print(str(spaces) + str(alpha) + ", " + str(beta))
                #print(spaces + str(action))
                score = self.min_value(new_state, player, depth=depth + 1, pruning=pruning, alpha=alpha, beta=beta)
                #print(spaces + str(action) + ": " + str(score))
                if score > biggest_score:
                    #print(spaces + "New Biggest Score")
                    biggest_score = score
            if pruning:
                if biggest_score >= beta:
                    #print(spaces + "pruned")
                    #print(spaces + "score: " + str(biggest_score) + " >= beta: " + str(beta))
                    return biggest_score
                alpha = max(alpha, biggest_score)
                #if biggest_score > alpha:
                    #print(spaces + "Alpha: " + str(alpha))

        return biggest_score
